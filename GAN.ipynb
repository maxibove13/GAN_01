{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic GAN implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd.variable import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda - GeForce MX130\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "  print(f\"{device} - {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "  print(f\"{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations. They can be chained together using Compose.\n",
    "transforms = transforms.Compose(\n",
    "    # Normalize to Mean Standard Deviation\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions (flatened)\n",
    "img_dims = (1, 28, 28)\n",
    "\n",
    "img_dim = img_dims[0] * img_dims[1] * img_dims[2] # 784\n",
    "\n",
    "# Defne dataset\n",
    "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some image functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vec(img):\n",
    "    return img.view(img.size(0), img_dim)\n",
    "\n",
    "def vec2img(vec):\n",
    "    return vec.view(vec.size(0), img_dims[0], img_dims[1], img_dims[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "def noise(size, noise_dim):\n",
    "    \"\"\"\n",
    "    Generates a 1-d vector of gaussian sampled random values\n",
    "    \"\"\"\n",
    "    n = Variable(torch.randn(size, noise_dim))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Model (Arquitecture)\n",
    "#### Create Discriminator and Generator classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024),\n",
    "            # Like RELU but it has a small slope for negative values instead of a flat slope. (In GANs is often a better choice than ReLU)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # To prevent overfitting (see README)\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    # noise_dim is the dimension of the latent noise that the generator takes as input\n",
    "    def __init__(self, noise_dim, img_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Initialize a Discriminator and Generator objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Disc object\n",
    "dis = Discriminator(img_dim).to(device)\n",
    "# Create a Gen object\n",
    "gen = Generator(noise_dim, img_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loss and optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4 # Learning rate\n",
    "batch_size = 100\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "# Here we tell which parameters (tensors) of the model we should update (dis.parameters(), gen.parameters())\n",
    "opt_dis = optim.Adam(dis.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn((batch_size, noise_dim)).to(device)\n",
    "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Discriminator: max [ log(D(real)) + log(1 - D(G(z)) ]\n",
    "def train_discriminator(D, optimizer, real, fake):\n",
    "    # Reset gradients to zero\n",
    "    D.zero_grad() # Clear out the gradients of all variables\n",
    "    \n",
    "    # Train on Real Data\n",
    "    ## Forward pass\n",
    "    pred_real = D(real).view(-1)\n",
    "    ## Loss\n",
    "    loss_real = criterion(pred_real, torch.ones_like(pred_real))\n",
    "    ## Backward pass\n",
    "    loss_real.backward()\n",
    "\n",
    "    # Train on Fake Data\n",
    "    ## Forward pass\n",
    "    pred_fake = D(fake).view(-1)\n",
    "    ## Loss\n",
    "    loss_fake = criterion(pred_fake, torch.zeros_like(pred_fake))\n",
    "    ## Backward pass\n",
    "    loss_fake.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    return loss_real + loss_fake, pred_real, pred_fake\n",
    "\n",
    "### Train Generator: min [ log(1 - D(G(z))) ] <-> max [ log(D(G(z))) ]\n",
    "def train_generator(G, D, optimizer, noise):\n",
    "    # Reset gradients to zero\n",
    "    G.zero_grad()\n",
    "\n",
    "    ## Forward pass\n",
    "    fake = G(noise)\n",
    "    ## Loss\n",
    "    # Calculate fake data: G(noise), evaluate Discriminator prediction D(G(noise)) and compare it to ones_like (we want D to output 1 from G outputs)\n",
    "    loss = criterion(D(fake), torch.ones_like(D(fake)))\n",
    "    ## Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200 - Loss D: 1.1602, Loss G: 0.6733]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (real, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m----> 8\u001b[0m         noisy \u001b[38;5;241m=\u001b[39m \u001b[43mnoise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m## 1. Train Discriminator\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Real image flatened and sent to device\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         real \u001b[38;5;241m=\u001b[39m Variable(img2vec(real))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set data\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        \n",
    "        \n",
    "        noisy = noise(batch_size, noise_dim).to(device)\n",
    "\n",
    "        ## 1. Train Discriminator\n",
    "        # Real image flatened and sent to device\n",
    "        real = Variable(img2vec(real)).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        # Generate fake data and detach (so gradients are not calculated for Gen)\n",
    "        fake = gen(noisy).detach()\n",
    "\n",
    "        # Train D\n",
    "        d_loss, d_pred_real, d_pred_fake = train_discriminator(dis, opt_dis, real, fake)\n",
    "\n",
    "        ## 2. Train Generator\n",
    "        g_loss = train_generator(gen, dis, opt_gen, noisy)\n",
    "\n",
    "\n",
    "        # On each epoch at the first mini-batch:\n",
    "        if batch_idx == 0:\n",
    "            # Print epochs and losses\n",
    "            print( \n",
    "                f\"Epoch [{epoch}/{num_epochs} - \"\n",
    "                f\"Loss D: {d_loss:.4f}, Loss G: {g_loss:.4f}]\"\n",
    "            )\n",
    "            # Get images for each epoch\n",
    "            with torch.no_grad(): # Context-manager that disable gradient calculation. It will reduce memory consumption.\n",
    "                fake = vec2img(gen(fixed_noise)) # Fake image with right dimensions\n",
    "                data = vec2img(real) # Real image with right dimensions\n",
    "                img_grid_fake = make_grid(fake, normalize=True)\n",
    "                img_grid_real = make_grid(data, normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"MNIST Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "\n",
    "                writer_real.add_image(\n",
    "                    \"MNIST Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "\n",
    "                step += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fec7b6ee39847465980d53c5e21723d5678090829ada2d3aaf8ff1ac066b3883"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv_gan_01': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
